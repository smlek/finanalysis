---
title: "Machine Learning on Earnings Results"
subtitle: ""
author: "Stan Mlekodaj"
date: "February 29, 2016"
output: html_document
---
```{r overhead, echo=FALSE, message=FALSE}
# General environment setup
# Clear variables
rm(list=ls())
# all par settings which could be changed.
old.par <- par(no.readonly = TRUE)
# Load required packages
library(knitr)
library(xtable)
#library(data.table)
#library(nnet)
#library(neuralnet)
#library(randomForest)
#library(RSNNS)
#library(ROCR)
library(caret)
```
```{r, ref.label="functions", echo=FALSE}
#runs chunk with all function definitions
```

## To-Do's
- Different datasets for classification/regression models



## General flow

    1. Define data inputs, ouputs. Make sure outputs are ~50/50 outcomes (not skewed)
        a. Feature selection/elimination, PCA
    2. normalize data (except ouputs when binary)
        a. dimensionality reduction/PCA (optional) 
    3. Split data into training, cross-validation, test sets
    4. Train model on training set
    5. Tune model parameters for best cross-validation performance
    6. Evaluate model on test set
    

## Lessons learned
- neuralnet method in train() expects numerical outputs, not factors
- GLM, rpart, H2o & other classification expect factor outputs

## Artificial data set for model testing
Idea:  Create input/output data set from a set of equations & random variables. 
This will create a known model with known correlations & variable importance.

```{r echo=FALSE}
# linear output data set
samples <- 1000

# linear output
# feat1 = rnorm(samples)
# feat2 = rnorm(samples)
# feat3 = 0.5 * (feat1 + rnorm(samples))
# feat4 = 0.9 * feat2
# feat5 = rnorm(samples)
# features <- data.frame(feat1, feat2, feat3, feat4, feat5)
# features <- scale(features,
#                   center = c(-5, 3, 50, 1000, -200), 
#                   scale = c(1/5, 1/3, 1/50, 1/1000, 1/200)
#                   )
# output = 7 + 0.1*feat1 + 0.2*feat2 + 0.3*feat3
# arbData <- data.frame(features, output)

# logistic output
output <- round(runif(samples))
feat1 <- 0.10 * output + rnorm(samples)
feat2 <- 0.25 * output + rnorm(samples)
feat3 <- 0.50 * output + rnorm(samples)
#eat3 <- 0.50 * (feat1 + rnorm(samples))
#feat4 <- 0.90 * feat2
feat4 <- 0.90 * output + rnorm(samples)
feat5 <- rnorm(samples)
arbData <- data.frame(feat1, feat2, feat3, feat4, feat5, output)

head(arbData)

```

    
## Data Definitions

```{r,echo=FALSE}
############ define data, model formula (training sets in rows) #######
# data directory
dataDir<-paste(Sys.getenv("HOME"),"/Rscripts/data/",sep="")

# input data file
dataFile <- "earningsData_cleaned_Robj"
load(paste(dataDir,dataFile,sep=""))
rawData <- earnData

# discard if zero After Earnings Change
rawData <- rawData[rawData$ChgAftEarn != 0, ]
# define SignChgAftEarn = pos/neg After Earnings Change
#rawData$SignChgAftEarn <- sign(rawData$ChgAftEarn)
rawData$SignChgAftEarn <- 0.5 * (sign(rawData$ChgAftEarn) + 1) # 0/1 ouput for down/up move

# covert to factor output
rawData$SignChgAftEarn <- factor(rawData$SignChgAftEarn, levels=c("0","1"), labels=c("Down","Up"))

# model formula definition (neuralnet, nnet)
# this approach ensures compatibility with neuralnet() which does not take "y ~ ."
n <- names(rawData)
allOutColNames <- c("ChgAftEarn","GapAftEarn","SignChgAftEarn")
outputColumn <- "SignChgAftEarn"
inColNames <- n[!(n %in% allOutColNames)]
fo <- as.formula(paste(outputColumn, "~", paste(inColNames, collapse = " + ")))

# input & output column indexes
inCols <- which(n %in% inColNames)
outCols <- which(n %in% outputColumn)

# Which columns to normalize - 0/1 outputs/inputs dont need scaling.
normCols <- inCols

deCorrelateInputs <- TRUE


#######################################################################


# ############ define data, model formula (training sets in rows) #######
# rawData <- arbData
# 
# # model formula definition (neuralnet, nnet)
# #fo <- formula("output ~ .")
# # this approach ensures compatibility with neuralnet() which does not take "y ~ ."
# n <- names(rawData)
# fo <- as.formula(paste("output ~", paste(names(rawData)[!n %in% "output"], collapse = " + ")))
# 
# # input & output column indexes
# inCols <- c(1:5)
# outCols <- c(6)
# 
# # Which columns to normalize - 0/1 outputs/inputs dont need scaling.
# normCols <- c(1:5)
# #normCols <- c()
# #######################################################################
allData <- rawData
data_size <- nrow(allData)
featureNames <- colnames(allData)

# shuffle & split data in training and test sets 
# Cross-Validation set omitted since using repeatedcv in caret
allData <- allData[sample(data_size), ]
splitIndex <- data_size * 0.8
trainData <- allData[1 : splitIndex, ]
testData <- allData[(splitIndex + 1) : data_size, ]

# # Feature Normalization
# allData[ , normCols] <- normalizeData(rawData[ , normCols], type = "norm") #also type = "0_1" or "center"
# # randomize rows
# allData <- allData[sample(data_size), ]
# 
# # split data in training, cross-validation, and test sets
# trainBreak <- data_size * 0.6 # 60% train
# cvBreak <- data_size * 0.8    # 20% cv, 20% test
# trainData <- allData[1 : trainBreak, ]
# cvData <- allData[(trainBreak + 1) : cvBreak, ]
# testData <- allData[(cvBreak + 1) : data_size, ]

# split into input & output matrixes 
trainInputs <- trainData[, inCols]
trainOutputs <- trainData[, outCols]
# cvInputs <- cvData[, inCols]
# cvOutputs <- cvData[, outCols]
testInputs <- testData[, inCols]
testOutputs <- testData[, outCols]

# Input Normalization - center/scale
preProcValues <- preProcess(trainInputs, method = c("center", "scale"))
trainInputs <- predict(preProcValues, trainInputs)
# test inputs normalized using training data normalization values
testInputs <- predict(preProcValues, testInputs)

# Remove correlated inputs
if(deCorrelateInputs) {
    corCols <- findCorrelation(cor(trainInputs), cutoff = 0.9, names = FALSE )
    trainInputs <- trainInputs[, -corCols]
    testInputs <- testInputs[, -corCols]
}


# # Input Normalization - PCA
# preProcValuesPCA <- preProcess(trainInputs, method = "pca")
# trainInputs <- predict(preProcValuesPCA, trainInputs)
# # test inputs normalized using training data normalization values
# testInputs <- predict(preProcValuesPCA, testInputs)
```

Raw Input Data Information:

- Number of input features:  `r length(inCols)`
- Number of outputs:         `r length(outCols)`
- Number of total data sets: `r data_size`


|            |Training Data            | Test Data              |
|------------|-------------------------|------------------------|
|Skewness    | `r table(trainOutputs)` | `r table(testOutputs)` |
|Data Sets   | `r nrow(trainData)`     | `r nrow(testData)`     |

Prediction Formula:  `r fo`

## Reduced Data Set

Correlated inputs removed? `r deCorrelateInputs `

Columns removed from original data:

`r names(trainInputs)[corCols]`

Reduced Input Data Information:

- Number of input features:  `r ncol(trainInputs)`
- Output:                 :  `r outputColumn`


## Decision Tree (rpart)

```{r,echo=FALSE}
cvCtrl <- trainControl(method = "repeatedcv", repeats = 3,
                       #summaryFunction = twoClassSummary,
                       classProbs = TRUE
                       )

set.seed(1)
rpartModel <- train(x = trainInputs,
                    y = trainOutputs,
                    method = "rpart",
                    tuneLength = 10,
                    metric = "Accuracy",
                    trControl = cvCtrl
                    )
rpartModel
rpartPred2 <- predict(rpartModel, testData)
confusionMatrix(rpartPred2, testOutputs)


```

## GLM

```{r,echo=FALSE}
cvCtrl <- trainControl(method = "repeatedcv", repeats = 3,
                       #summaryFunction = twoClassSummary,
                       classProbs = TRUE
                       )
set.seed(1)
# glmModel <- train(fo, data = rbind(trainData, cvData), method = "glm",
#                   family = binomial(),
#                   #tuneLength = 30,
#                   metric = "Accuracy",
#                   trControl = cvCtrl
#                   )
glmModel <- train(x = trainInputs,
                  y = trainOutputs,
                  #y = factor(trainOutputs, levels=c("0","1"), labels=c("Down","Up")),
                  method = "glm",
                  family = binomial(),
                  #tuneLength = 30,
                  metric = "Accuracy",
                  trControl = cvCtrl
                  )
glmModel
glmModelPredict <- predict(glmModel, testInputs)
confusionMatrix(glmModelPredict, testOutputs)
```


## nnet

```{r,echo=FALSE}
cvCtrl <- trainControl(method = "none", repeats = 1,
                       number = 1,
                       #summaryFunction = twoClassSummary,
                       classProbs = TRUE
                       )
tune_grid <- expand.grid(size = c(50),
                         decay = 5e-4
                         )
set.seed(1)
nnetModel <- train(x = trainInputs,
                 y = trainOutputs,
                 #y = as.numeric(trainOutputs),
                 #y = factor(trainOutputs, levels=c("0","1"), labels=c("Down","Up")),
                 method = "nnet",
                 #tuneLength = 30,
                 #metric = "Accuracy",
                 trControl = cvCtrl,
                 tuneGrid = tune_grid,
                 #entropy = TRUE,
                 abstol = 0.01,
                 maxit = 500,
                 MaxNWts = 3000,
                 linout = FALSE
                 )
nnetModel
nnModelPredict <- predict(nnetModel, testInputs)
caret::confusionMatrix(nnModelPredict, testOutputs)
```

## Neural Network (No Tuning, Single Run)
Regression only via Caret package

```{r,echo=FALSE, eval=FALSE}
cvCtrl <- trainControl(method = "none", repeats = 1,
                       number = 1,
                       #summaryFunction = twoClassSummary,
                       classProbs = TRUE
                       )
tune_grid <- expand.grid(layer1 = c(5),
                      layer2 = 0,
                      layer3 = 0
                      )
set.seed(1)
nnModel <- train(x = trainInputs,
                 y = trainOutputs,
                 #y = factor(trainOutputs, levels=c("0","1"), labels=c("Down","Up")),
                 method = "neuralnet",
                 #tuneLength = 30,
                # metric = "Accuracy",
                 trControl = cvCtrl,
                 tuneGrid = tune_grid,
                 threshold = 0.01,
                 stepmax = 1e+5,
                 learningrate = 0.01,
                 lifesign = "full",
                 algorithm = "rprop+",
                 err.fct = "ce",
                 act.fct = "logistic",
                 linear.output = FALSE                
                 )
nnModel
nnModelPredict <- predict(nnModel, testInputs)
confusionMatrix(nnModelPredict, testOutputs)
```

## MLP

```{r,echo=FALSE}
# cvCtrl <- trainControl(method = "repeatedcv", repeats = 1,
#                        #summaryFunction = twoClassSummary,
#                        classProbs = TRUE
#                        )
cvCtrl <- trainControl(method = "none", number = 1,
                       summaryFunction = twoClassSummary,
                       classProbs = TRUE
                       )
#tune_grid <- expand.grid(size = c(1,3,5))
tune_grid <- expand.grid(size = c(5))

set.seed(1)
mlpModel <- train(x = trainInputs,
                 y = trainOutputs,
                 #y = factor(trainOutputs, levels=c("0","1"), labels=c("Down","Up")),
                 method = "mlp",
                 #tuneLength = 30,
                 metric = "ROC",
                 trControl = cvCtrl,
                 tuneGrid = tune_grid,
                 learnFunc="Quickprop", 
                 learnFuncParams=c(0.1, 2.0, 0.0001, 0.1),
                 maxit=500,
                 linOut = FALSE            
                 )
mlpModel
nnModelPredict <- predict(mlpModel, testInputs)
caret::confusionMatrix(nnModelPredict, testOutputs)
#caret::confusionMatrix(nnModelPredict, factor(testOutputs, levels=c("0","1"), labels=c("Down","Up")))
```

## MLP Weight Decay

```{r,echo=FALSE}
cvCtrl <- trainControl(method = "repeatedcv", repeats = 1,
                       summaryFunction = twoClassSummary,
                       classProbs = TRUE
                       )
# cvCtrl <- trainControl(method = "none", number = 1,
#                        summaryFunction = twoClassSummary,
#                        classProbs = TRUE
#                        )
#tune_grid <- expand.grid(size = c(1,3,5))
tune_grid <- expand.grid(size = c(5,10,20),
                         decay = c(0.01, 0.05)
                         )

set.seed(1)
mlpwdModel <- train(x = trainInputs,
                 y = trainOutputs,
                 #y = factor(trainOutputs, levels=c("0","1"), labels=c("Down","Up")),
                 method = "mlpWeightDecay",
                 #tuneLength = 30,
                 metric = "ROC",
                 trControl = cvCtrl,
                 tuneGrid = tune_grid,
                 maxit=500,
                 linOut = FALSE            
                 )
mlpwdModel
nnModelPredict <- predict(mlpwdModel, testInputs)
caret::confusionMatrix(nnModelPredict, testOutputs)

```

## MLP Multilayer with Weight Decay

```{r,echo=FALSE}
# cvCtrl <- trainControl(method = "repeatedcv", repeats = 1,
#                        #summaryFunction = twoClassSummary,
#                        classProbs = TRUE
#                        )
cvCtrl <- trainControl(method = "none", number = 1,
                       #summaryFunction = twoClassSummary,
                       classProbs = TRUE
                       )
#tune_grid <- expand.grid(size = c(1,3,5))
tune_grid <- expand.grid(layer1 = c(5),
                         layer2 = 5,
                         layer3 = 0,
                         decay = 0.01
                         )

set.seed(1)
mlpwdMLModel <- train(x = trainInputs,
                 y = trainOutputs,
                 #y = factor(trainOutputs, levels=c("0","1"), labels=c("Down","Up")),
                 method = "mlpWeightDecayML",
                 #tuneLength = 30,
                 metric = "Accuracy",
                 trControl = cvCtrl,
                 tuneGrid = tune_grid,
                 maxit=500,
                 linOut = FALSE            
                 )
mlpwdMLModel
nnModelPredict <- predict(mlpwdMLModel, testInputs)
caret::confusionMatrix(nnModelPredict, testOutputs)

```

## DNN

```{r,echo=FALSE}
# cvCtrl <- trainControl(method = "repeatedcv", repeats = 1,
#                        #summaryFunction = twoClassSummary,
#                        classProbs = TRUE
#                        )
cvCtrl <- trainControl(method = "none", number = 1,
                       #summaryFunction = twoClassSummary,
                       classProbs = TRUE
                       )
#tune_grid <- expand.grid(size = c(1,3,5))
tune_grid <- expand.grid(layer1 = c(20),
                         layer2 = 10,
                         layer3 = 0,
                         hidden_dropout = 0,
                         visible_dropout = 0
                         )

set.seed(1)
dnnModel <- train(x = trainInputs,
                 y = trainOutputs,
                 #y = factor(trainOutputs, levels=c("0","1"), labels=c("Down","Up")),
                 method = "dnn",
                 #tuneLength = 30,
                 metric = "Accuracy",
                 trControl = cvCtrl,
                 tuneGrid = tune_grid
                 )
dnnModel
dnnModelPredict <- predict(dnnModel, testInputs)
caret::confusionMatrix(dnnModelPredict, testOutputs)

```

# H20
```{r,echo=FALSE}
library(h2o)
h2o.init(nthreads = -1)
#demo(h2o.deeplearning)



h2oModel <- h2o.deeplearning(x = inColNames, 
                             y = outputColumn, 
                             training_frame = as.h2o(trainData),
                             validation_frame = as.h2o(testData),
                             activation = "Rectifier",
                             hidden = c(16, 16, 16),
                             epochs = 100,
                             nfolds = 5,
                             l1 = 1e-5
)
h2oModel
# h2oModelPredict <- predict(h2oModel, as.h2o(testData))
# h2operformance = h2o.performance(model = h2oModel, valid = TRUE)
# h2operformance = h2o.performance(model = h2oModel)
# print(h2operformance)


```



```{r functions, echo=FALSE, eval=FALSE}
# Define functions in this chunk

##############  NEEDS VERIFICATION
# Takes predicted & target values, computes best prediction cutoff for max accuracy.
# ONLY FOR BINARY CLASSIFICATION - targets values must have only 2 values
# Returns cutoff and resulting accuracy. Also plots 4 metrics vs. cutoffs
getCutoffAndPlot <- function(predicted, targets) {
   
#     par(mfrow=c(1,1))
#     plotROC(predicted, targets, main = "ROC Curve") # ROC curve
    
    # make predicitons object using ROCR
    pred_obj <- ROCR::prediction(predicted, targets) # nerualnet also has prediction()
    # performance - need decision on most important metric
    perf_obj <- ROCR::performance(pred_obj, "acc", "cutoff")
    maxMetricInd <- which.max(perf_obj@y.values[[1]])    # index of metric max
    cutoff <- pred_obj@cutoffs[[1]][maxMetricInd]     # cutoff for max metric 
    perfMetric <- perf_obj@y.values[[1]][maxMetricInd]   # metric value at cutoff
    perfMetricName <- perf_obj@y.name                    # metric name
    
    # Plot several metrics vs. cutoff
    par(mfrow=c(2,2))
    plot(ROCR::performance(pred_obj, "acc", "cutoff"), ylim = c(0,1), main = "Accuracy")
    plot(ROCR::performance(pred_obj, "f", "cutoff"), ylim = c(0,1), main = "F-Score")
    plot(ROCR::performance(pred_obj, "phi", "cutoff"), ylim = c(-1,1), main = "Phi Corr. Coef.")
    plot(ROCR::performance(pred_obj, "sar", "cutoff"), main = "SAR Multi-Score")
    
    return(list(cutoff, perfMetricName, perfMetric))
}


```


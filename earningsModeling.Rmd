---
title: "Machine Learning on Earnings Results"
subtitle: ""
author: "Stan Mlekodaj"
date: "February 29, 2016"
output: html_document
---
```{r overhead, echo=FALSE, message=FALSE}
# General environment setup
# Clear variables
rm(list=ls())
# all par settings which could be changed.
old.par <- par(no.readonly = TRUE)
# Load required packages
#library(knitr)
#library(xtable)
#library(data.table)
#library(nnet)
#library(neuralnet)
#library(randomForest)
library(RSNNS)
#library(ROCR)
library(caret)
```
```{r, ref.label="functions", echo=FALSE}
#runs chunk with all function definitions
```

## To-Do's
- Different datasets for classification/regression models



## General flow

    1. Define data inputs, ouputs. Make sure outputs are ~50/50 outcomes (not skewed)
        a. Feature selection/elimination, PCA
    2. normalize data (except ouputs when binary)
        a. dimensionality reduction/PCA (optional) 
        b. other transforms to make N(0,1)
    3. Split data into training, cross-validation, test sets
    4. Train model on training set
    5. Tune model parameters for best cross-validation performance
    6. Evaluate model on test set
    

## Lessons learned
- neuralnet method in train() expects numerical outputs, not factors
- GLM, rpart, H2o & other classification expect factor outputs
- can't use mlpWeightDecay and mlpWeightDecayML thru caret

## Data Definitions

```{r,echo=FALSE}
############ define data, model formula (training sets in rows) #######
# data directory
dataDir <- paste(Sys.getenv("HOME"),"/Rscripts/data/",sep="")

# input data file
dataFile <- "earningsData_cleaned_Robj"
load(paste(dataDir,dataFile,sep=""))

# Apply data filters
f1 <- earnData$ChgAftEarn != 0      # discard if zero After Earnings Change
f2 <- earnData$Market.Cap > 50      # > $50Mln
f3 <- earnData$P.B < 100
f4 <- earnData$P.E < 200
f5 <- (earnData$ChgAftEarn > 0.03) | (earnData$ChgAftEarn < -0.03)
f6 <- TRUE
f7 <- TRUE
f8 <- TRUE
f9 <- TRUE
f10 <- TRUE

rawData <- earnData[ f1 & f2 & f3 & f4 & f5 & f6 & f7 & f8 & f9 & f10, ]

# define SignChgAftEarn = pos/neg After Earnings Change
rawData$SignChgAftEarn <- sign(rawData$ChgAftEarn)
#rawData$SignChgAftEarn <- 0.5 * (sign(rawData$ChgAftEarn) + 1) # 0/1 ouput for down/up move

# covert to factor output
#rawData$SignChgAftEarn <- factor(rawData$SignChgAftEarn, levels=c("0","1"), labels=c("Down","Up"))
rawData$SignChgAftEarn <- factor(rawData$SignChgAftEarn, levels=c("-1","1"), labels=c("Down","Up"))

allOutColNames <- c("ChgAftEarn","GapAftEarn","SignChgAftEarn") # assume others are all inputs
outputColumn <- "SignChgAftEarn"

linearOutput <- FALSE        # linear output=TRUE, factor output=FALSE
normalizeOutputs <- FALSE    # don't normalize factors
inputNormType <- "norm"     # type = "norm", "0_1" or "center"
outputNormType <- "0_1" 
mlpHiddenActFunc <- "Act_TanH" # only for RSNNS::mlp()
deCorrelateInputs <- TRUE
#######################################################################
```

```{r,echo=FALSE}
allData <- rawData

# input & output column indexes
n <- names(allData)
inCols <- which( !(n %in% allOutColNames) )
outCols <- which(n %in% outputColumn)

# shuffle & split data in training and test sets 
data_size <- nrow(allData)
allData <- allData[sample(data_size), ]
splitIndex <- data_size * 0.8
trainInputs <- allData[1 : splitIndex, inCols]
trainOutputs <- allData[1 : splitIndex, outCols]
testInputs <- allData[(splitIndex + 1) : data_size, inCols]
testOutputs <- allData[(splitIndex + 1) : data_size, outCols]

# Remove correlated inputs (caret)
if(deCorrelateInputs) {
    corCols <- findCorrelation(cor(trainInputs), cutoff = 0.9, names = FALSE )
    if(length(corCols) > 0) {
            trainInputs <- trainInputs[, -corCols]
            testInputs <- testInputs[, -corCols]  
    }
    
}
inColNames <- colnames(trainInputs)

# Input Normalization (RSNNS)
trainInputs <- normalizeData(trainInputs, type = inputNormType) #also type = "0_1" or "center"
# # test inputs normalized using training data normalization values
testInputs <- normalizeData(testInputs, type = attr(trainInputs, "normParams"))

# # Input Normalization - PCA
# preProcValuesPCA <- preProcess(trainInputs, method = "pca")
# trainInputs <- predict(preProcValuesPCA, trainInputs)
# # test inputs normalized using training data normalization values
# testInputs <- predict(preProcValuesPCA, testInputs)

# Output Normalization (RSNNS) 
if(normalizeOutputs) {
    trainOutputs <- normalizeData(trainOutputs, type = outputNormType) #also type = "0_1" or "center"
    testOutputs <- normalizeData(testOutputs, type = attr(trainOutputs, "normParams")) 
}

# reconstruct train & test dataframes
trainData <- data.frame(trainInputs, trainOutputs)
colnames(trainData) <- c(inColNames, outputColumn)
testData <- data.frame(testInputs, testOutputs)
colnames(testData) <- c(inColNames, outputColumn)

```

Raw Input Data Information:

- Number of input features:  `r length(inCols)`
- Number of outputs:         `r length(outCols)`
- Number of total data sets: `r data_size`


|            |Training Data            | Test Data              |
|------------|-------------------------|------------------------|
|Skewness    | `r table(trainOutputs)` | `r table(testOutputs)` |
|Data Sets   | `r nrow(trainData)`     | `r nrow(testData)`     |


## Reduced Data Set

Correlated inputs removed? `r deCorrelateInputs `

Columns removed from original data:

`r names(allData)[inCols %in% corCols]`

Reduced Input Data Information:

- Number of input features:  `r ncol(trainInputs)`
- Output:                 :  `r outputColumn`

## Input Data Histograms

```{r,echo=FALSE}
#i <- 2
for (i in 1:length(inColNames)){
    hist(trainData[, i],
         breaks = 30,
         main = inColNames[i]
         )
    
}


```

## H20 Deep Learning
```{r,echo=FALSE}
library(h2o)
h2o.init(ip = "localhost", port = 54321, nthreads = -2, max_mem_size = "3g")
#demo(h2o.deeplearning)

h2oModel <- h2o.deeplearning(x = inColNames, #number indexes also seem to work
                             y = outputColumn, 
                             training_frame = as.h2o(trainData),
                             validation_frame = as.h2o(testData),
                             #activation = "Rectifier",
                             activation = "Tanh",
                             hidden = c(32),
                             epochs = 5000,
                             train_samples_per_iteration = -2, # Auto
                             #train_samples_per_iteration = 0,  # one epoch
                             #nfolds = 5,
                             l1 = 1e-5,
                             l2 = 1e-5,
                             score_interval = 0.1, #time in seconds
                             score_training_samples = 0, # 0=all
                             stopping_tolerance = 0.01,
                             stopping_rounds = 5,
                             export_weights_and_biases = TRUE,
                             variable_importances = TRUE
                            )
h2oModel
plot(h2oModel)
h2o.weights(h2oModel, matrix_id = 1)
h2o.biases(h2oModel)
h2o.scoreHistory(h2oModel)
h2o.varimp(h2oModel)
#feat.l1 <- h2o.deepfeatures(h2oModel, data = as.h2o(trainData), layer = 1)
# h2o.no_progress()
# h2o.show_progress()
h2o.shutdown(prompt=FALSE)

# h2oModelPredict <- predict(h2oModel, as.h2o(testData))
# h2operformance = h2o.performance(model = h2oModel, valid = TRUE)
# h2operformance = h2o.performance(model = h2oModel)
#print(h2operformance)


```

## H20 Deep Learning - Grid Search
```{r,echo=FALSE}
library(h2o)
h2o.init(ip = "localhost", port = 54321, nthreads = -2, max_mem_size = "3g")

hyper_params <- list(
    hidden = list(c(1), c(3), c(10))
    )

grid <- h2o.grid(algorithm = "deeplearning",
                 grid_id = "grid_1",
                 hyper_params = hyper_params,
                 x = inColNames, #number indexes also seem to work
                 y = outputColumn, 
                 training_frame = as.h2o(trainData),
                 validation_frame = as.h2o(testData),
                 #activation = "Rectifier",
                 activation = "Tanh",
                 #hidden = c(3),
                 epochs = 5000,
                 train_samples_per_iteration = -2, # Auto
                 #train_samples_per_iteration = 0,  # one epoch
                 #nfolds = 5,
                 l1 = 1e-5,
                 l2 = 1e-5,
                 score_interval = 0.1, #time in seconds
                 score_training_samples = 0, # 0=all
                 stopping_tolerance = 0.01,
                 stopping_rounds = 5,
                 export_weights_and_biases = TRUE,
                 variable_importances = TRUE
                )
grid
grid <- h2o.getGrid("grid_1",sort_by="mse",decreasing=FALSE)
grid@summary_table[1,]
h2oModel <- h2o.getModel(grid@model_ids[[1]])
h2oModel
plot(h2oModel)
h2o.weights(h2oModel)
h2o.biases(h2oModel)
h2o.scoreHistory(h2oModel)
h2o.varimp(h2oModel)
feat.l1 <- h2o.deepfeatures(h2oModel, data = as.h2o(trainData), layer = 1)
# h2o.no_progress()
# h2o.show_progress()
h2o.shutdown(prompt=FALSE)



# h2oModelPredict <- predict(h2oModel, as.h2o(testData))
# h2operformance = h2o.performance(model = h2oModel, valid = TRUE)
# h2operformance = h2o.performance(model = h2oModel)
#print(h2operformance)


```

## H20 GLM
```{r,echo=FALSE}
h2oModel <- h2o.glm(x = inColNames, 
                    y = outputColumn, 
                    training_frame = as.h2o(trainData),
                    validation_frame = as.h2o(testData),
                    family = "binomial"
                    #nfolds = 5
                    )
h2oModel
# h2operformance = h2o.performance(model = h2oModel, valid = TRUE)
# h2operformance = h2o.performance(model = h2oModel)
# print(h2operformance)

```




